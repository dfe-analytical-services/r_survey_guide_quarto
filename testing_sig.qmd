---
title: "Testing for significance"  
---

You can use `07_sig_testing.R` as a reference for this section.

This section provides code for different types of significance testing. For survey data, the non-parametric tests are most common.

::: callout-note
## WEIGHTS

SPSS calculates weighted results slightly differently to R. SPSS rounds weighted counts to the nearest whole number, and then bases any subsequent statistics off that.

R does not round, so results are slightly more accurate. You may find that results do not exactly match SPSS output (difference of \<0.5pp) depending on how your contractor has calculated their weights.

[Get more information about weights here.](https://www.ibm.com/support/pages/some-options-fractional-weights-crosstabs)
:::

::: callout-important
## Which test should I use?

The `sjstats` package provides useful documentation to help you decide which test is most appropriate. Run `?chi_squared_test` in the console and a guide will pop up in the "Help" panel in the right-hand side.
:::

## Load packages, functions and read in data {#load-packages-functions-and-read-in-data}

You need to make sure you load the required packages and custom functions if you haven't already. You also need to read in the required data for this script.

Even if you read in the data before, we recommend you re-run this code so that you're working with a data set without any alterations you may have done to it in previous scripts.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project.
:::

```{r, eval=FALSE}

# load packages and custom functions --------------------------------------


source("00_packages_and_functions.R")


# read in data for this script --------------------------------------------


TELSdata <- haven::read_spss("data/TELS_DUMMY_DATA.sav"
                             #ensures that user-defined missing values in the spss file
                             # are read into R as NA
                             # If you want to bring in these codes into analysis (e.g. you might be interested
                             # in the share who refused) change to TRUE.
                             , user_na=FALSE)


```

## Non-parametric tests

Non-parametric tests do not assume a distribution of the data (e.g. normal), do not require knowledge about the population and are suitable for ordinal data. For these reasons, these tests are most appropriate for use in survey data.

### Chi-squared {#chi-squared}

Chi-squared tests are used to work out if there is significant association between two independent variables. For example, if you want to determine if there is a significant association between gender (male/female) and preference for a new product (like/dislike). You can collect data from a survey where each participant is only surveyed once (unpaired). You use an unpaired chi-squared test to see if the observed frequencies of preferences differ significantly from what would be expected by chance.

Data should be categorical to run this test, so you should re-code ordinal data if you want to use chi-squared for it.

In the example below, we will re-code `CurrentSit` as it is ordinal and then do a chi-squared test on the re-coded `CurrentSit` variable and `FSM_DV`.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}

#re-coding currentsit so it's two categories instead of 4
TELSdata <- TELSdata %>%
  dplyr::mutate(CurrentSit_recode=dplyr::case_when(
    CurrentSit %in% c(1,2) ~ 1,
    CurrentSit %in% c(4,5) ~ 2))

#do a chi-squared test on currentsit and fsm_dv
chisq <- sjstats::chi_squared_test(TELSdata,
                                   select = "CurrentSit_recode",
                                   by ="FSM_DV",
                                   weights= "TechEd_W3_cross")

#view results in the console
chisq

```

After running the code above, you should see in the console that the p value is not \<0.05 so the effect is not significant.

#### Longitudinal data

If you have a longitudinal data set, you might want to test the association between variables in a pre- and post- scenario. i.e. whether a learner's view has changed over time. In this case you would want to do a paired chi-squared test.

Here is an example of how to do this.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}


chisq <- sjstats::chi_squared_test(TELSdata,
                                   select = "CurrentSit_recode",
                                   #define groups for paired test
                                   #note this column does not exist in the data
                                   by ="wave",
                                   weights= "TechEd_W3_cross",
                                   #do a paired test
                                   paired=TRUE)

#view results in the console
chisq
```

You should see in the console that the p-value is \<0.05. This means that there is a significant difference in `CurrentSit_recode` between the different waves in the dummy data. However, the effect size (shown by Ï•) is very small, indicating that the practical impact of this difference is minimal.

### Mann-Whitney U / Kruskal-Wallis

#### Mann-Whitney U

This test is designed for comparing ordinal data across two groups for two independent samples, e.g., comparing the customer satisfaction ratings (on a scale of 1 to 5) between two different stores. Since the ratings are ordinal and may not be normally distributed, you use the Mann-Whitney U test to compare the two independent groups.

You can Interpret the scores as follows:

-   Small effect \>= 0.1

-   Medium effect \>= 0.3

-   Large effect \>= 0.5

You should combine the interpretation of these scores with the interpretation of the p-value as well. In the example below, we will compare `CurrentSit` and `FF_Sex` and interpret both values.

##### Levels and categories

When working with SPSS data in R, the categories in grouped data like `FF_Sex` can be referred to as groups, levels, and factors. It is important to be familiar with these terms as you may come across them in different documentation.

::: callout-important
## Unused levels and `sjstats::mann_whitney_test()`

If the variable that you're using for the `by` parameter for `sjstats::mann_whitney_test()` has more than two levels (categories), even if those levels (categories) are unused, they need to be dropped. Otherwise, the incorrect labels will be used for the ranking scores.
:::

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}
#check how many levels (categories) there are for FF_SEX in the data

unique(TELSdata$FF_Sex) # there are more than 2

# Use mutate to convert FF_Sex to a factor and drop unused levels (categories) for sex
TELSdata <- TELSdata %>%
  dplyr::mutate(FF_Sex = droplevels(as.factor(FF_Sex)))

#carry out test 
ranktest1 <- sjstats::mann_whitney_test(TELSdata,
                                        select="CurrentSit",
                                        by="FF_Sex",
                                        weights = "TechEd_W3_cross")
#view results
ranktest1

```

You should see in the console the result show:

-   there is no significant difference (p\>0.01), and the effect is small (R=0.05).

-   group 1: Female had a higher rank score.

    -   in our case the scale is inverted so higher number = more likely to be unfulfilled.

-   with a higher rank score, we would say that the female participants are more likely to be "unfulfilled" but with a low significance with a small effect, this is likely due to random variation rather than a true difference between the groups.

#### Kruskal-Wallis

If your group variable has more than two categories, use the Kruskal-Wallis. For example, if you want to compare the effectiveness of three different diets on weight loss. You measure the weight loss of participants after following each diet for a month. Since the data may not be normally distributed and you have more than two groups, you use the Kruskal-Wallis test. The first variable in the formula is the dependent variable and the second is the independent variable or groups you want to test.

In the example below, we're going to compare `CurrentSit` and `TLPathway_Str`. This means we are comparing fulfillment (shown by `CurrentSit`) across the different types of pathways in the data (shown by `TLPathway_Str`).

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}

#create survey design object that outlines weights
weight <- survey::svydesign(
  #- ~1 means that there is a single constant term 
  #i.e. each observation is treated as a separate
  # sampling unit with equal weight.
  
  ids = ~1,
  #outline the weight variable 
  weights = ~TechEd_W3_cross,
  data = TELSdata)


kruskalwallis <- survey::svyranktest(
  # The first variable in the formula is the dependent variable
  # the second is the independent variable or groups you want to test.
  formula = CurrentSit ~ TLPathway_Str,
  #use survey design object to define weight
  design=weight,
  # specify test 
  test="KruskalWallis")

#view results in the console
kruskalwallis

```

After running this code, you should see in the console that the p-value is \> 0.05. This means we cannot reject the null hypothesis so there is no statistically significant difference in the distributions of `FF_Age2022` across the different `TLPathway_Str` groups.

After Kruskal-Wallis, you might want to do post-hoc comparisons to identify which category is significantly different. You would use Dunn's test for this, but we haven't found a version in R that can handle weights.

### Wilcoxon

The Wilcoxon test is like the Mann-Whitney U test but for paired samples, i.e. when you want to test a pre- and post- effect with the same people. For example, if you are testing the effect of a new drug on blood pressure, you measure the blood pressure of patients before and after taking the drug. Since the data are paired and may not be normally distributed, you use the Wilcoxon signed-rank test to compare the two related samples.

In our example below, we are comparing how fulfilled (this is in `CurrentSit`) participants feel at two different points in time.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}
#wilcoxon without weights
wilcoxon <- sjstats::wilcoxon_test(TELSdata,
                                   select = "CurrentSit",
                                   by = "wave"
)

#view results in the console
wilcoxon

```

After you run the code above, you should see in the console that the p-value is \> 0.05. This means we cannot reject the null hypothesis as there is no statistically significant difference in `CurrentSit` between the different `wave` variations in the dummy data. The small effect size (r = 0.04) also suggests that any difference is minimal.

Now we are going to do the same test but with weights.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}

#wilcoxon with weights

design <- survey::svydesign(ids = ~1,
                            data = TELSdata,
                            weights = ~TechEd_W3_cross)

wilcoxon_weighted <- survey::svyranktest(CurrentSit ~ wave,
                    design,
                    test = "wilcoxon")

#view results in the console
wilcoxon_weighted

```

::: callout-important
The output of this code will say "Design-based KruskalWallis test". However, this test is a Wilcoxon test, and this message is due to the similarities in survey design between Wilcoxon and Kruskal Wallis tests.
:::

After running the code above, you should see in the console that the p-value is \> 0.05. This means we cannot reject the null hypothesis as there is no statistically significant difference in the mean rank scores between `CurrentSit` over the different waves. The difference in mean rank score is also very small (0.045), indicating minimal variation between the groups.

## Parametric tests

Parametric tests assume normally distributed data, knowledge about the population parameters and typically requires interval data. Since most of survey data is nominal/ordinal and rarely normally distributed, these tests are appropriate in the minority of cases.

### T-test

T-tests are used to determine whether two groups are significantly different from each other. There are three main types, and the dependent variable needs to be continuous for all of them, but the independent variable differs.

::: callout-warning
## Data types

Ensure that you have the correct data types for all tests but ensure this for t-tests and z-tests in particular as the functions are stricter with data types. They require numeric (continuous) type data.
:::

#### Independent Samples T-test:

The independent variable is typically binary, representing two different groups (e.g., male vs. female, treatment vs. control). For example, if you want to compare the average test scores of students from two different schools, use an independent t-test. This will determine if there is a significant difference between the means of the two independent groups.

In the example below, we will be comparing the average age by sex.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}

#check that the dependent variable (age) has a numeric data type
class(TELSdata$FF_Age2022)

#change the data type from character to numeric (to reflect continuous values)

TELSdata <- TELSdata %>%
  dplyr::mutate(FF_Age2022=as.numeric(FF_Age2022))

# test whether male and females are significantly different
# from each other in age

ttest <- sjstats::t_test(TELSdata,
                         #define test/dependent variable
                         #this should be continuous
                         select = "age",
                         #define the groups we want to test
                         by = "sex",
                         #give column name for the weight
                         weights = "TechEd_W3_cross")

#view the results
ttest

```

After you run the code above, you should see in the console that there is not a statistically significant difference in the mean ages between males and females as the p-vale is \< 0.05. The small effect size (Cohen's d = 0.11) also suggests that any difference in ages is minimal and not practically significant.

#### Paired Samples T-test:

The independent variable represents two related measurements (e.g., pre-test vs. post-test scores for the same individuals). This is helpful when you have a longitudinal data set, and you want to see if there is a difference over time. For example, if you measure the performance of employees before and after a training program, you can use a paired t-test. This is because the data are paired (same employees measured twice), you use a paired t-test to compare the means of the two related groups.

In the example below, we will compare the income of individuals in the data in two different time points. We will add the 'paired' operator and split by `wave` as that column indicates the time points.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}

ttest2 <- sjstats::t_test(TELSdata,
                          select = "income",
                          #split by variable that has the groups
                          by = "wave",
                          weights = "TechEd_W3_cross",
                          #set paired to true
                          paired=TRUE)

#view results in the console
ttest2

```

After you run the code above, you should see in the console that there is a statistically significant difference in income between the waves as the p-value is \< 0.05. The effect size (Cohen's d = -0.06) suggests that, while the difference is statistically significant, the magnitude of this difference is very small in practical terms.

#### One-Sample T-test:

The independent variable is a single group compared to a known value or population mean. In the example below, we will compare income variable to its mean.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](#load-packages-functions-and-read-in-data).
:::

```{r, eval=FALSE}
# Perform one-sample t-test
result <- sjstats::t_test(TELSdata,
                 select = "income",
                 mu = 50052.28)
#view results in the console
result
```

After you run the code above, you should see in the console that there is no statistically significant difference between the mean income of our sample and the hypothetical population mean of 50,052.28. The effect size is very small (Cohen's d = -0.04), suggesting that the difference is negligible in practical terms.

### Z-test

::: callout-warning
## Data types

Ensure that you have the correct data types for all tests but ensure this for t-tests and z-tests in particular as the functions are stricter with data types. They require numeric (continuous) type data.
:::

Z-tests are used to determine whether there is a significant difference between sample and population means or between the means of two samples. For example, if you are comparing the average height of a sample of adult men to the known population mean height, you would use a z-test. Since you know the population standard deviation and have a large sample size, you use a z-test to determine if the sample mean significantly differs from the population mean.

Another example of when it is useful is when comparing the percentage of people who are satisfied between two groups (e.g. IoT (Institution of Technology) learner vs. non-IoT (non-Institution of Technology) learner).

We're going to outline weighted counts and sample sizes in the example below. e.g. 86 in 185 (46%), 528 in 948 (56%).

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [reload the packages and custom functions](setting_up_workspace.qmd).
:::

```{r, eval=FALSE}

# determine if two proportions in large samples are significantly different
# using dummy data

# outlining weighted count for first group
p1<-86
# outlining sample size for first group
n1<-185
# outlining weighted count for second group
p2<-528
# outlining sample size for second group
n2<-948

result <-stats::prop.test(
  #give weighted counts for each group
  c(p1,p2),
  #give the sample size for each group
  n=c(n1,n2))

#print result in the console
result
#extract z statistic
zstatistic <-result$statistic
```

After you run the code above, you should see in the console that the p-value (0.02648) is \< 0.05. This means we can reject the null hypothesis and there is a statistically significant difference between the two proportions.

## Combine the learning

It's important to bear in mind that the code in this guide can be combined to make your analysis more suitable to your needs.

In the example below, we will do a chi-squared test on `CurrentSit_recode` and `FSM_DV` after [filtering](formatting_filtering.qmd#filtering) the data set for respondents that have finished or are currently doing a T-level qualification.

::: callout-tip
## Run the code

Run the code below in the corresponding script in your project. If you are starting from this point in the guide, remember to run lines from **the top of the script** to [read in the data and reload the packages and custom functions](setting_up_workspace.qmd). Make sure to run the lines for [re-coding](#chi-squared) the `CurrentSit` variable as well for this test.
:::

```{r, eval=FALSE}

#filter the data
tels_t_level <- TELSdata %>%
  dplyr::filter(FinishTLevel %in% c(1,2))

#do a chi-squared test on currentsit and fsm_dv
chisq <- sjstats::chi_squared_test(tels_t_level,
                                   select = "CurrentSit_recode",
                                   by ="FSM_DV",
                                   weights= "TechEd_W3_cross")

```
